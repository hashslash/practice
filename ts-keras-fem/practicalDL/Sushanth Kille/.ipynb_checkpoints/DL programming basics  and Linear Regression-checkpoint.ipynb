{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf and tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mminval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmaxval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Outputs random values from a uniform distribution.\n",
       "\n",
       "The generated values follow a uniform distribution in the range\n",
       "`[minval, maxval)`. The lower bound `minval` is included in the range, while\n",
       "the upper bound `maxval` is excluded.\n",
       "\n",
       "For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must\n",
       "be specified explicitly.\n",
       "\n",
       "In the integer case, the random integers are slightly biased unless\n",
       "`maxval - minval` is an exact power of two.  The bias is small for values of\n",
       "`maxval - minval` significantly smaller than the range of the output (either\n",
       "`2**32` or `2**64`).\n",
       "\n",
       "Examples:\n",
       "\n",
       ">>> tf.random.uniform(shape=[2])\n",
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
       ">>> tf.random.uniform(shape=[], minval=-1., maxval=0.)\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=-...>\n",
       ">>> tf.random.uniform(shape=[], minval=5, maxval=10, dtype=tf.int64)\n",
       "<tf.Tensor: shape=(), dtype=int64, numpy=...>\n",
       "\n",
       "The `seed` argument produces a deterministic sequence of tensors across\n",
       "multiple calls. To repeat that sequence, use `tf.random.set_seed`:\n",
       "\n",
       ">>> tf.random.set_seed(5)\n",
       ">>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
       ">>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
       ">>> tf.random.set_seed(5)\n",
       ">>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
       ">>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
       "\n",
       "Without `tf.random.set_seed` but with a `seed` argument is specified, small\n",
       "changes to function graphs or previously executed operations will change the\n",
       "returned value. See `tf.random.set_seed` for details.\n",
       "\n",
       "Args:\n",
       "  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
       "  minval: A Tensor or Python value of type `dtype`, broadcastable with\n",
       "    `maxval`. The lower bound on the range of random values to generate\n",
       "    (inclusive).  Defaults to 0.\n",
       "  maxval: A Tensor or Python value of type `dtype`, broadcastable with\n",
       "    `minval`. The upper bound on the range of random values to generate\n",
       "    (exclusive). Defaults to 1 if `dtype` is floating point.\n",
       "  dtype: The type of the output: `float16`, `float32`, `float64`, `int32`,\n",
       "    or `int64`.\n",
       "  seed: A Python integer. Used in combination with `tf.random.set_seed` to\n",
       "    create a reproducible sequence of tensors across multiple calls.\n",
       "  name: A name for the operation (optional).\n",
       "\n",
       "Returns:\n",
       "  A tensor of the specified shape filled with random uniform values.\n",
       "\n",
       "Raises:\n",
       "  ValueError: If `dtype` is integral and `maxval` is not specified.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.random.uniform([10000],0,10,tf.int64,name=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([5, 6, 6, ..., 5, 0, 9], dtype=int64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor.numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tensor_np = tensor.numpy()\n",
    "print(type(tensor_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1006.,  985., 1009.,  957., 1039., 1013., 1019., 1009.,  984.,\n",
       "         979.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(tensor_np)\n",
    "# providing a numpy array will make the plt count the values \n",
    "# and provide the SET of values as x and COUNT of SET as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(weight=0.1,bias=0.1,count=1000):\n",
    "    x=tf.random.uniform(shape=[count],)\n",
    "    return x;\n",
    "x=create_data(count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9., 11.,  4.,  9.,  6., 12., 10., 13., 15., 11.]),\n",
       " array([0.03070343, 0.12758973, 0.22447605, 0.32136238, 0.41824868,\n",
       "        0.515135  , 0.6120213 , 0.7089076 , 0.80579394, 0.9026802 ,\n",
       "        0.99956656], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(weight=0.1,bias=0.1,count=1000):\n",
    "    x=tf.random.uniform(shape=[count],)\n",
    "    noise=tf.random.normal([count],mean=0.0,stddev=0.01)\n",
    "    y= x * weight + bias + noise\n",
    "    return x,y;\n",
    "\n",
    "w=0.1\n",
    "b=0.1\n",
    "x,y=create_data(w,b,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27b2c42e308>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(x,y,'bo') # blue and cirlces\n",
    "plt.plot(x,y,'b.') # blue and points\n",
    "\n",
    "# x in X_AXIS and y in Y_AXIS\n",
    "\n",
    "plt.plot([0,1],[b,w+b],'g-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Prediction\n",
    "#### Aim for least loss(MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y,y_pred):\n",
    "    return tf.reduce_mean(tf.square(y-y_pred))\n",
    "\n",
    "def predict(x,w=0.01,b=0.01):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.023533512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0060288836, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00010162365, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0057517313, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y,predict(x,   0   ,   0  )))\n",
    "print(mean_squared_error(y,predict(x,   0.05   ,   0.05  )))\n",
    "print(mean_squared_error(y,predict(x,   0.1   ,   0.1  )))\n",
    "print(mean_squared_error(y,predict(x,   0.15   ,   0.15  )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27b2c4a4708>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,'b.')\n",
    "\n",
    "plt.plot([0,1],[b,w+b],'g-')\n",
    "\n",
    "plt.plot([0,1],[0.15,0.3],'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Implementation\n",
    "### Vary the weight and bias to \n",
    "### Minimizing Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "See the [variable guide](https://tensorflow.org/guide/variable).\n",
       "\n",
       "A variable maintains shared, persistent state manipulated by a program.\n",
       "\n",
       "The `Variable()` constructor requires an initial value for the variable, which\n",
       "can be a `Tensor` of any type and shape. This initial value defines the type\n",
       "and shape of the variable. After construction, the type and shape of the\n",
       "variable are fixed. The value can be changed using one of the assign methods.\n",
       "\n",
       ">>> v = tf.Variable(1.)\n",
       ">>> v.assign(2.)\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
       ">>> v.assign_add(0.5)\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.5>\n",
       "\n",
       "The `shape` argument to `Variable`'s constructor allows you to construct a\n",
       "variable with a less defined shape than its `initial_value`:\n",
       "\n",
       ">>> v = tf.Variable(1., shape=tf.TensorShape(None))\n",
       ">>> v.assign([[1.]])\n",
       "<tf.Variable ... shape=<unknown> dtype=float32, numpy=array([[1.]], ...)>\n",
       "\n",
       "Just like any `Tensor`, variables created with `Variable()` can be used as\n",
       "inputs to operations. Additionally, all the operators overloaded for the\n",
       "`Tensor` class are carried over to variables.\n",
       "\n",
       ">>> w = tf.Variable([[1.], [2.]])\n",
       ">>> x = tf.constant([[3., 4.]])\n",
       ">>> tf.matmul(w, x)\n",
       "<tf.Tensor:... shape=(2, 2), ... numpy=\n",
       "  array([[3., 4.],\n",
       "         [6., 8.]], dtype=float32)>\n",
       ">>> tf.sigmoid(w + x)\n",
       "<tf.Tensor:... shape=(2, 2), ...>\n",
       "\n",
       "When building a machine learning model it is often convenient to distinguish\n",
       "between variables holding trainable model parameters and other variables such\n",
       "as a `step` variable used to count training steps. To make this easier, the\n",
       "variable constructor supports a `trainable=<bool>`\n",
       "parameter. `tf.GradientTape` watches trainable variables by default:\n",
       "\n",
       ">>> with tf.GradientTape(persistent=True) as tape:\n",
       "...   trainable = tf.Variable(1.)\n",
       "...   non_trainable = tf.Variable(2., trainable=False)\n",
       "...   x1 = trainable * 2.\n",
       "...   x2 = non_trainable * 3.\n",
       ">>> tape.gradient(x1, trainable)\n",
       "<tf.Tensor:... shape=(), dtype=float32, numpy=2.0>\n",
       ">>> assert tape.gradient(x2, non_trainable) is None  # Unwatched\n",
       "\n",
       "Variables are automatically tracked when assigned to attributes of types\n",
       "inheriting from `tf.Module`.\n",
       "\n",
       ">>> m = tf.Module()\n",
       ">>> m.v = tf.Variable([1.])\n",
       ">>> m.trainable_variables\n",
       "(<tf.Variable ... shape=(1,) ... numpy=array([1.], dtype=float32)>,)\n",
       "\n",
       "This tracking then allows saving variable values to\n",
       "[training checkpoints](https://www.tensorflow.org/guide/checkpoint), or to\n",
       "[SavedModels](https://www.tensorflow.org/guide/saved_model) which include\n",
       "serialized TensorFlow graphs.\n",
       "\n",
       "Variables are often captured and manipulated by `tf.function`s. This works the\n",
       "same way the un-decorated function would have:\n",
       "\n",
       ">>> v = tf.Variable(0.)\n",
       ">>> read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
       ">>> read_and_decrement()\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.1>\n",
       ">>> read_and_decrement()\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.2>\n",
       "\n",
       "Variables created inside a `tf.function` must be owned outside the function\n",
       "and be created only once:\n",
       "\n",
       ">>> class M(tf.Module):\n",
       "...   @tf.function\n",
       "...   def __call__(self, x):\n",
       "...     if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
       "...       self.v = tf.Variable(x)\n",
       "...     return self.v * x\n",
       ">>> m = M()\n",
       ">>> m(2.)\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n",
       ">>> m(3.)\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
       ">>> m.v\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
       "\n",
       "See the `tf.function` documentation for details.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Creates a new variable with value `initial_value`. (deprecated arguments)\n",
       "\n",
       "Warning: SOME ARGUMENTS ARE DEPRECATED: `(caching_device)`. They will be removed in a future version.\n",
       "Instructions for updating:\n",
       "A variable's value can be manually cached by calling tf.Variable.read_value() under a tf.device scope. The caching_device argument does not work properly.\n",
       "\n",
       "Args:\n",
       "  initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
       "    which is the initial value for the Variable. The initial value must have\n",
       "    a shape specified unless `validate_shape` is set to False. Can also be a\n",
       "    callable with no argument that returns the initial value when called. In\n",
       "    that case, `dtype` must be specified. (Note that initializer functions\n",
       "    from init_ops.py must first be bound to a shape before being used here.)\n",
       "  trainable: If `True`, GradientTapes automatically watch uses of this\n",
       "    variable. Defaults to `True`, unless `synchronization` is set to\n",
       "    `ON_READ`, in which case it defaults to `False`.\n",
       "  validate_shape: If `False`, allows the variable to be initialized with a\n",
       "    value of unknown shape. If `True`, the default, the shape of\n",
       "    `initial_value` must be known.\n",
       "  caching_device: Optional device string describing where the Variable\n",
       "    should be cached for reading.  Defaults to the Variable's device. If not\n",
       "    `None`, caches on another device.  Typical use is to cache on the device\n",
       "    where the Ops using the Variable reside, to deduplicate copying through\n",
       "    `Switch` and other conditional statements.\n",
       "  name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
       "    uniquified automatically.\n",
       "  variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
       "    Variable object with its contents, referencing the variable's nodes in\n",
       "    the graph, which must already exist. The graph is not changed.\n",
       "    `variable_def` and the other arguments are mutually exclusive.\n",
       "  dtype: If set, initial_value will be converted to the given type. If\n",
       "    `None`, either the datatype will be kept (if `initial_value` is a\n",
       "    Tensor), or `convert_to_tensor` will decide.\n",
       "  import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
       "    used when initializing from protocol buffer.\n",
       "  constraint: An optional projection function to be applied to the variable\n",
       "    after being updated by an `Optimizer` (e.g. used to implement norm\n",
       "    constraints or value constraints for layer weights). The function must\n",
       "    take as input the unprojected Tensor representing the value of the\n",
       "    variable and return the Tensor for the projected value (which must have\n",
       "    the same shape). Constraints are not safe to use when doing asynchronous\n",
       "    distributed training.\n",
       "  synchronization: Indicates when a distributed a variable will be\n",
       "    aggregated. Accepted values are constants defined in the class\n",
       "    `tf.VariableSynchronization`. By default the synchronization is set to\n",
       "    `AUTO` and the current `DistributionStrategy` chooses when to\n",
       "    synchronize.\n",
       "  aggregation: Indicates how a distributed variable will be aggregated.\n",
       "    Accepted values are constants defined in the class\n",
       "    `tf.VariableAggregation`.\n",
       "  shape: (optional) The shape of this variable. If None, the shape of\n",
       "    `initial_value` will be used. When setting this argument to\n",
       "    `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
       "    can be assigned with values of different shapes.\n",
       "\n",
       "Raises:\n",
       "  ValueError: If both `variable_def` and initial_value are specified.\n",
       "  ValueError: If the initial value is not specified, or does not have a\n",
       "    shape and `validate_shape` is `True`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\n",
       "\u001b[1;31mType:\u001b[0m           VariableMetaclass\n",
       "\u001b[1;31mSubclasses:\u001b[0m     VariableV1, DistributedVariable, AggregatingVariable, AutoCastVariable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.Variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mread_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Assigns a new value to the variable.\n",
       "\n",
       "This is essentially a shortcut for `assign(self, value)`.\n",
       "\n",
       "Args:\n",
       "  value: A `Tensor`. The new value for this variable.\n",
       "  use_locking: If `True`, use locking during the assignment.\n",
       "  name: The name of the operation to be created\n",
       "  read_value: if True, will return something which evaluates to the new\n",
       "    value of the variable; if False will return the assign op.\n",
       "\n",
       "Returns:\n",
       "  A `Tensor` that will hold the new value of this variable after\n",
       "  the assignment has completed.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.Variable.assign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mread_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Subtracts a value from this variable.\n",
       "\n",
       "This is essentially a shortcut for `assign_sub(self, delta)`.\n",
       "\n",
       "Args:\n",
       "  delta: A `Tensor`. The value to subtract from this variable.\n",
       "  use_locking: If `True`, use locking during the operation.\n",
       "  name: The name of the operation to be created\n",
       "  read_value: if True, will return something which evaluates to the new\n",
       "    value of the variable; if False will return the assign op.\n",
       "\n",
       "Returns:\n",
       "  A `Tensor` that will hold the new value of this variable after\n",
       "  the subtraction has completed.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.Variable.assign_sub?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mread_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Subtracts a value from this variable.\n",
       "\n",
       "This is essentially a shortcut for `assign_sub(self, delta)`.\n",
       "\n",
       "Args:\n",
       "  delta: A `Tensor`. The value to subtract from this variable.\n",
       "  use_locking: If `True`, use locking during the operation.\n",
       "  name: The name of the operation to be created\n",
       "  read_value: if True, will return something which evaluates to the new\n",
       "    value of the variable; if False will return the assign op.\n",
       "\n",
       "Returns:\n",
       "  A `Tensor` that will hold the new value of this variable after\n",
       "  the subtraction has completed.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.Variable.assign_sub?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatch_accessed_variables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Record operations for automatic differentiation.\n",
       "\n",
       "Operations are recorded if they are executed within this context manager and\n",
       "at least one of their inputs is being \"watched\".\n",
       "\n",
       "Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
       "where `trainable=True` is default in both cases) are automatically watched.\n",
       "Tensors can be manually watched by invoking the `watch` method on this context\n",
       "manager.\n",
       "\n",
       "For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
       "be computed as:\n",
       "\n",
       "```python\n",
       "x = tf.constant(3.0)\n",
       "with tf.GradientTape() as g:\n",
       "  g.watch(x)\n",
       "  y = x * x\n",
       "dy_dx = g.gradient(y, x) # Will compute to 6.0\n",
       "```\n",
       "\n",
       "GradientTapes can be nested to compute higher-order derivatives. For example,\n",
       "\n",
       "```python\n",
       "x = tf.constant(3.0)\n",
       "with tf.GradientTape() as g:\n",
       "  g.watch(x)\n",
       "  with tf.GradientTape() as gg:\n",
       "    gg.watch(x)\n",
       "    y = x * x\n",
       "  dy_dx = gg.gradient(y, x)     # Will compute to 6.0\n",
       "d2y_dx2 = g.gradient(dy_dx, x)  # Will compute to 2.0\n",
       "```\n",
       "\n",
       "By default, the resources held by a GradientTape are released as soon as\n",
       "GradientTape.gradient() method is called. To compute multiple gradients over\n",
       "the same computation, create a persistent gradient tape. This allows multiple\n",
       "calls to the gradient() method as resources are released when the tape object\n",
       "is garbage collected. For example:\n",
       "\n",
       "```python\n",
       "x = tf.constant(3.0)\n",
       "with tf.GradientTape(persistent=True) as g:\n",
       "  g.watch(x)\n",
       "  y = x * x\n",
       "  z = y * y\n",
       "dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
       "dy_dx = g.gradient(y, x)  # 6.0\n",
       "del g  # Drop the reference to the tape\n",
       "```\n",
       "\n",
       "By default GradientTape will automatically watch any trainable variables that\n",
       "are accessed inside the context. If you want fine grained control over which\n",
       "variables are watched you can disable automatic tracking by passing\n",
       "`watch_accessed_variables=False` to the tape constructor:\n",
       "\n",
       "```python\n",
       "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
       "  tape.watch(variable_a)\n",
       "  y = variable_a ** 2  # Gradients will be available for `variable_a`.\n",
       "  z = variable_b ** 3  # No gradients will be available since `variable_b` is\n",
       "                       # not being watched.\n",
       "```\n",
       "\n",
       "Note that when using models you should ensure that your variables exist when\n",
       "using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
       "first iteration not have any gradients:\n",
       "\n",
       "```python\n",
       "a = tf.keras.layers.Dense(32)\n",
       "b = tf.keras.layers.Dense(32)\n",
       "\n",
       "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
       "  tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
       "                           # `a.variables` will return an empty list and the\n",
       "                           # tape will not be watching anything.\n",
       "  result = b(a(inputs))\n",
       "  tape.gradient(result, a.variables)  # The result of this computation will be\n",
       "                                      # a list of `None`s since a's variables\n",
       "                                      # are not being watched.\n",
       "```\n",
       "\n",
       "Note that only tensors with real or complex dtypes are differentiable.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Creates a new GradientTape.\n",
       "\n",
       "Args:\n",
       "  persistent: Boolean controlling whether a persistent gradient tape\n",
       "    is created. False by default, which means at most one call can\n",
       "    be made to the gradient() method on this object.\n",
       "  watch_accessed_variables: Boolean controlling whether the tape will\n",
       "    automatically `watch` any (trainable) variables accessed while the tape\n",
       "    is active. Defaults to True meaning gradients can be requested from any\n",
       "    result computed in the tape derived from reading a trainable `Variable`.\n",
       "    If False users must explicitly `watch` any `Variable`s they want to\n",
       "    request gradients from.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     LossScaleGradientTape\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.GradientTape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0munconnected_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mUnconnectedGradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Computes the gradient using operations recorded in context of this tape.\n",
       "\n",
       "Args:\n",
       "  target: a list or nested structure of Tensors or Variables to be\n",
       "    differentiated.\n",
       "  sources: a list or nested structure of Tensors or Variables. `target`\n",
       "    will be differentiated against elements in `sources`.\n",
       "  output_gradients: a list of gradients, one for each element of\n",
       "    target. Defaults to None.\n",
       "  unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
       "    alters the value which will be returned if the target and sources are\n",
       "    unconnected. The possible values and effects are detailed in\n",
       "    'UnconnectedGradients' and it defaults to 'none'.\n",
       "\n",
       "Returns:\n",
       "  a list or nested structure of Tensors (or IndexedSlices, or None),\n",
       "  one for each element in `sources`. Returned structure is the same as\n",
       "  the structure of `sources`.\n",
       "\n",
       "Raises:\n",
       "  RuntimeError: if called inside the context of the tape, or if called more\n",
       "   than once on a non-persistent tape.\n",
       "  ValueError: if the target is a variable or if unconnected gradients is\n",
       "   called with an unknown value.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.GradientTape.gradient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trying out GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 10.0 23.025852 1.0\n",
      "1.1 11.0 33.52449 1.3980799\n",
      "1.2 12.0 49.014847 1.9725025\n",
      "1.3 13.0 71.97888 2.8062494\n",
      "1.4 14.0 106.176414 4.02327\n",
      "1.5 15.0 157.3235 5.809475\n",
      "1.6 16.0 234.14099 8.444851\n",
      "1.7 17.0 349.97943 12.352738\n",
      "1.8 18.0 525.3445 18.17567\n",
      "1.9 19.0 791.83435 26.892538\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable( 1.0 )\n",
    "b = tf.Variable( 10.0 )\n",
    "\n",
    "for _ in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #operate\n",
    "        c = b ** a        \n",
    "        \n",
    "        #frame for gradient\n",
    "        gradient = tape.gradient( c , [ a , b ] )\n",
    "        \n",
    "        print( a.numpy() , b.numpy() , gradient[0].numpy() , gradient[1].numpy() )\n",
    "        \n",
    "        # change or assign\n",
    "        b.assign_add( 1 )\n",
    "        a.assign( b / 10 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error( y , y_pred ):\n",
    "    return tf.reduce_mean( tf.square( y - y_pred ) )\n",
    "\n",
    "def root_mean_squared_error( y , y_pred ):\n",
    "    return tf.sqrt( tf.reduce_mean( tf.square( y - y_pred ) ) )\n",
    "\n",
    "def predict( x , w , b ):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0   :   0.016453539952635765   -   0.0301330778747797 --------- 0.02353351190686226\n",
      "step 50   :   0.0796620324254036   -   0.1116870641708374 --------- 0.00012954065459780395\n",
      "step 100   :   0.0883345752954483   -   0.10710641741752625 --------- 0.0001093776518246159\n",
      "step 150   :   0.09311257302761078   -   0.1045827567577362 --------- 0.00010325756738893688\n",
      "step 200   :   0.09574492275714874   -   0.10319238156080246 --------- 0.00010139994992641732\n",
      "step 250   :   0.09719519317150116   -   0.10242637991905212 --------- 0.0001008361141430214\n",
      "step 300   :   0.09799420088529587   -   0.10200435668230057 --------- 0.00010066496906802058\n",
      "step 350   :   0.09843439608812332   -   0.10177185386419296 --------- 0.0001006130114546977\n",
      "step 400   :   0.09867693483829498   -   0.10164374858140945 --------- 0.00010059725173050538\n",
      "step 450   :   0.09881053119897842   -   0.10157318413257599 --------- 0.00010059248597826809\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0.0) # should be a variable because it changes\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "learning_rate = tf.constant( 0.1 ) #doesn't change\n",
    "steps = 500\n",
    "\n",
    "for step in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = predict( x , w , b )\n",
    "        loss = mean_squared_error( y , y_pred )\n",
    "        \n",
    "        gradients = tape.gradient( loss , [ w , b ]) #get change in loss because of w and b\n",
    "        # d(loss)/d(w)   and    d(loss)/d(b)\n",
    "        \n",
    "        w.assign_sub(gradients[0] * learning_rate) # subtract the change step by step\n",
    "        b.assign_sub(gradients[1] * learning_rate)\n",
    "        \n",
    "        if step % 50 == 0 :\n",
    "            print(\"step {}   :   {}   -   {} --------- {}\".format( step , w.numpy() , b.numpy() , loss ).center(50) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0   :   1.036843180656433   -   -0.9064370393753052 --------- 0.6987613439559937\n",
      "step 50   :   0.20905694365501404   -   0.043342772871255875 --------- 0.03738534078001976\n",
      "step 100   :   0.0721927061676979   -   0.050700217485427856 --------- 0.060838647186756134\n",
      "step 150   :   0.07300178706645966   -   0.05231248587369919 --------- 0.0629514828324318\n",
      "step 200   :   0.0730646550655365   -   0.052432164549827576 --------- 0.06310947239398956\n",
      "step 250   :   0.07306940853595734   -   0.05244117230176926 --------- 0.06312135607004166\n",
      "step 300   :   0.07306976616382599   -   0.05244176834821701 --------- 0.06312216818332672\n",
      "step 350   :   0.07306976616382599   -   0.05244176834821701 --------- 0.06312216818332672\n",
      "step 400   :   0.07306976616382599   -   0.05244176834821701 --------- 0.06312216818332672\n",
      "step 450   :   0.07306976616382599   -   0.05244176834821701 --------- 0.06312216818332672\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(1.0) # should be a variable because it changes\n",
    "b = tf.Variable(-1.0)\n",
    "\n",
    "learning_rate = tf.constant( 0.1 ) #doesn't change\n",
    "steps = 500\n",
    "\n",
    "\n",
    "for step in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = predict( x , w , b )\n",
    "        loss = root_mean_squared_error( y , y_pred )\n",
    "        \n",
    "        gradients = tape.gradient( loss , [ w , b ]) #get change in loss because of w and b\n",
    "        # d(loss)/d(w)   and    d(loss)/d(b)\n",
    "        \n",
    "        w.assign_sub(gradients[0] * learning_rate) # subtract the change step by step\n",
    "        b.assign_sub(gradients[1] * learning_rate)\n",
    "        \n",
    "        if step % 50 == 0 :\n",
    "            print(\"step {}   :   {}   -   {} --------- {}\".format( step , w.numpy() , b.numpy() , loss ).center(50) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### learning rate should not be too slow so that steps never make it near to true value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mendpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mretstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return evenly spaced numbers over a specified interval.\n",
       "\n",
       "Returns `num` evenly spaced samples, calculated over the\n",
       "interval [`start`, `stop`].\n",
       "\n",
       "The endpoint of the interval can optionally be excluded.\n",
       "\n",
       ".. versionchanged:: 1.16.0\n",
       "    Non-scalar `start` and `stop` are now supported.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "start : array_like\n",
       "    The starting value of the sequence.\n",
       "stop : array_like\n",
       "    The end value of the sequence, unless `endpoint` is set to False.\n",
       "    In that case, the sequence consists of all but the last of ``num + 1``\n",
       "    evenly spaced samples, so that `stop` is excluded.  Note that the step\n",
       "    size changes when `endpoint` is False.\n",
       "num : int, optional\n",
       "    Number of samples to generate. Default is 50. Must be non-negative.\n",
       "endpoint : bool, optional\n",
       "    If True, `stop` is the last sample. Otherwise, it is not included.\n",
       "    Default is True.\n",
       "retstep : bool, optional\n",
       "    If True, return (`samples`, `step`), where `step` is the spacing\n",
       "    between samples.\n",
       "dtype : dtype, optional\n",
       "    The type of the output array.  If `dtype` is not given, infer the data\n",
       "    type from the other input arguments.\n",
       "\n",
       "    .. versionadded:: 1.9.0\n",
       "\n",
       "axis : int, optional\n",
       "    The axis in the result to store the samples.  Relevant only if start\n",
       "    or stop are array-like.  By default (0), the samples will be along a\n",
       "    new axis inserted at the beginning. Use -1 to get an axis at the end.\n",
       "\n",
       "    .. versionadded:: 1.16.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "samples : ndarray\n",
       "    There are `num` equally spaced samples in the closed interval\n",
       "    ``[start, stop]`` or the half-open interval ``[start, stop)``\n",
       "    (depending on whether `endpoint` is True or False).\n",
       "step : float, optional\n",
       "    Only returned if `retstep` is True\n",
       "\n",
       "    Size of spacing between samples.\n",
       "\n",
       "\n",
       "See Also\n",
       "--------\n",
       "arange : Similar to `linspace`, but uses a step size (instead of the\n",
       "         number of samples).\n",
       "geomspace : Similar to `linspace`, but with numbers spaced evenly on a log\n",
       "            scale (a geometric progression).\n",
       "logspace : Similar to `geomspace`, but with the end points specified as\n",
       "           logarithms.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.linspace(2.0, 3.0, num=5)\n",
       "array([2.  , 2.25, 2.5 , 2.75, 3.  ])\n",
       ">>> np.linspace(2.0, 3.0, num=5, endpoint=False)\n",
       "array([2. ,  2.2,  2.4,  2.6,  2.8])\n",
       ">>> np.linspace(2.0, 3.0, num=5, retstep=True)\n",
       "(array([2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)\n",
       "\n",
       "Graphical illustration:\n",
       "\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> N = 8\n",
       ">>> y = np.zeros(N)\n",
       ">>> x1 = np.linspace(0, 10, N, endpoint=True)\n",
       ">>> x2 = np.linspace(0, 10, N, endpoint=False)\n",
       ">>> plt.plot(x1, y, 'o')\n",
       "[<matplotlib.lines.Line2D object at 0x...>]\n",
       ">>> plt.plot(x2, y + 0.5, 'o')\n",
       "[<matplotlib.lines.Line2D object at 0x...>]\n",
       ">>> plt.ylim([-0.5, 1])\n",
       "(-0.5, 1)\n",
       ">>> plt.show()\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\numpy\\core\\function_base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.linspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return coordinate matrices from coordinate vectors.\n",
       "\n",
       "Make N-D coordinate arrays for vectorized evaluations of\n",
       "N-D scalar/vector fields over N-D grids, given\n",
       "one-dimensional coordinate arrays x1, x2,..., xn.\n",
       "\n",
       ".. versionchanged:: 1.9\n",
       "   1-D and 0-D cases are allowed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x1, x2,..., xn : array_like\n",
       "    1-D arrays representing the coordinates of a grid.\n",
       "indexing : {'xy', 'ij'}, optional\n",
       "    Cartesian ('xy', default) or matrix ('ij') indexing of output.\n",
       "    See Notes for more details.\n",
       "\n",
       "    .. versionadded:: 1.7.0\n",
       "sparse : bool, optional\n",
       "    If True a sparse grid is returned in order to conserve memory.\n",
       "    Default is False.\n",
       "\n",
       "    .. versionadded:: 1.7.0\n",
       "copy : bool, optional\n",
       "    If False, a view into the original arrays are returned in order to\n",
       "    conserve memory.  Default is True.  Please note that\n",
       "    ``sparse=False, copy=False`` will likely return non-contiguous\n",
       "    arrays.  Furthermore, more than one element of a broadcast array\n",
       "    may refer to a single memory location.  If you need to write to the\n",
       "    arrays, make copies first.\n",
       "\n",
       "    .. versionadded:: 1.7.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X1, X2,..., XN : ndarray\n",
       "    For vectors `x1`, `x2`,..., 'xn' with lengths ``Ni=len(xi)`` ,\n",
       "    return ``(N1, N2, N3,...Nn)`` shaped arrays if indexing='ij'\n",
       "    or ``(N2, N1, N3,...Nn)`` shaped arrays if indexing='xy'\n",
       "    with the elements of `xi` repeated to fill the matrix along\n",
       "    the first dimension for `x1`, the second for `x2` and so on.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This function supports both indexing conventions through the indexing\n",
       "keyword argument.  Giving the string 'ij' returns a meshgrid with\n",
       "matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\n",
       "In the 2-D case with inputs of length M and N, the outputs are of shape\n",
       "(N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\n",
       "with inputs of length M, N and P, outputs are of shape (N, M, P) for\n",
       "'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\n",
       "illustrated by the following code snippet::\n",
       "\n",
       "    xv, yv = np.meshgrid(x, y, sparse=False, indexing='ij')\n",
       "    for i in range(nx):\n",
       "        for j in range(ny):\n",
       "            # treat xv[i,j], yv[i,j]\n",
       "\n",
       "    xv, yv = np.meshgrid(x, y, sparse=False, indexing='xy')\n",
       "    for i in range(nx):\n",
       "        for j in range(ny):\n",
       "            # treat xv[j,i], yv[j,i]\n",
       "\n",
       "In the 1-D and 0-D case, the indexing and sparse keywords have no effect.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "index_tricks.mgrid : Construct a multi-dimensional \"meshgrid\"\n",
       "                 using indexing notation.\n",
       "index_tricks.ogrid : Construct an open multi-dimensional \"meshgrid\"\n",
       "                 using indexing notation.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> nx, ny = (3, 2)\n",
       ">>> x = np.linspace(0, 1, nx)\n",
       ">>> y = np.linspace(0, 1, ny)\n",
       ">>> xv, yv = np.meshgrid(x, y)\n",
       ">>> xv\n",
       "array([[0. , 0.5, 1. ],\n",
       "       [0. , 0.5, 1. ]])\n",
       ">>> yv\n",
       "array([[0.,  0.,  0.],\n",
       "       [1.,  1.,  1.]])\n",
       ">>> xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\n",
       ">>> xv\n",
       "array([[0. ,  0.5,  1. ]])\n",
       ">>> yv\n",
       "array([[0.],\n",
       "       [1.]])\n",
       "\n",
       "`meshgrid` is very useful to evaluate functions on a grid.\n",
       "\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> x = np.arange(-5, 5, 0.1)\n",
       ">>> y = np.arange(-5, 5, 0.1)\n",
       ">>> xx, yy = np.meshgrid(x, y, sparse=True)\n",
       ">>> z = np.sin(xx**2 + yy**2) / (xx**2 + yy**2)\n",
       ">>> h = plt.contourf(x,y,z)\n",
       ">>> plt.show()\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\src\\python\\envs\\ml\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.meshgrid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
